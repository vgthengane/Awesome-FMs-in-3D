# Awesome-Multimodal-in-3D
A comprehensive surevy on Multimodal Models in 3D

<!-- <font size=5><center><b> Table of Contents </b> </center></font> -->
## Table of Contents

- [Classification](#classification)
- [Detection](#detection)
- - [Open Vocabulary Detection](ov-detection)
- - [Open World Detection](ow-detection)
- [Segmentation](#segmentation)
- [Tracking](#tracking)
- [Localization](#localization)
- [Retrival](#retrival)
- [Scene Understanding](#scene-understanding)
- [Editing and Manupulation](#editing-and-manupulation)
- [Generation](#generation)
- [Grounding](#grounding)
- [Captioning](#captioning)
- [Pose Estimation](#pose-estimation)
- [Question Answering](#question-answering)
- [Pretraining](#pretraining)
- [Matching](#matching)
---


## Generation



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[CLIP-Sculptor: Zero-Shot Generation of High-Fidelity and Diverse Shapes from Natural Language](https://arxiv.org/abs/2211.01427) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2211.01427) | nan | nan | 2022 |
|[SINC: Spatial Composition of 3D Human Motions for Simultaneous Action Generation](http://arxiv.org/abs/2304.10417) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2304.10417) | nan | nan | 2023 |
|[Make-An-Animation: Large-Scale Text-conditional 3D Human Motion Generation](https://openaccess.thecvf.com/content/ICCV2023/html/Azadi_Make-An-Animation_Large-Scale_Text-conditional_3D_Human_Motion_Generation_ICCV_2023_paper) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://openaccess.thecvf.com/content/ICCV2023/html/Azadi_Make-An-Animation_Large-Scale_Text-conditional_3D_Human_Motion_Generation_ICCV_2023_paper) | nan | nan | 2023 |
|[Articulated 3D Head Avatar Generation using Text-to-Image Diffusion Models](http://arxiv.org/abs/2307.04859) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2307.04859) | nan | nan | 2023 |
|[Multimodal 3D Hand Pose Enhancement for Sign Language](https://www.semanticscholar.org/paper/Multimodal-3D-Hand-Pose-Enhancement-for-Sign-Budria/97f78bc084235d858df6659e5d1470e7aeac831e) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://www.semanticscholar.org/paper/Multimodal-3D-Hand-Pose-Enhancement-for-Sign-Budria/97f78bc084235d858df6659e5d1470e7aeac831e) | nan | nan | 2022 |
|[Text and Image Guided 3D Avatar Generation and Manipulation](http://arxiv.org/abs/2202.06079) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2202.06079) | nan | nan | 2022 |
|[TexFusion: Synthesizing 3D Textures with Text-Guided Image Diffusion Models](https://openaccess.thecvf.com//content/ICCV2023/html/Cao_TexFusion_Synthesizing_3D_Textures_with_Text-Guided_Image_Diffusion_Models_ICCV_2023_paper) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://openaccess.thecvf.com//content/ICCV2023/html/Cao_TexFusion_Synthesizing_3D_Textures_with_Text-Guided_Image_Diffusion_Models_ICCV_2023_paper) | nan | nan | 2023 |
|[DreamAvatar: Text-and-Shape Guided 3D Human Avatar Generation via Diffusion Models](http://arxiv.org/abs/2304.00916) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2304.00916) | nan | nan | 2023 |
|[Guide3D: Create 3D Avatars from Text and Image Guidance](http://arxiv.org/abs/2308.09705) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2308.09705) | nan | nan | 2023 |
|[High-Fidelity Generalized Emotional Talking Face Generation with Multi-Modal Emotion Space Learning](https://arxiv.org/pdf/2305.02572) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/pdf/2305.02572) | nan | nan | 2023 |
|[MRIS: A Multi-modal Retrieval Approach for Image Synthesis on Diverse Modalities](http://arxiv.org/abs/2303.10249) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2303.10249) | nan | nan | 2023 |
|[Text2Tex: Text-driven Texture Synthesis via Diffusion Models](http://arxiv.org/abs/2303.11396) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2303.11396) | nan | nan | 2023 |
|[Fantasia3D: Disentangling Geometry and Appearance for High-quality Text-to-3D Content Creation](http://arxiv.org/abs/2303.13873) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2303.13873) | nan | nan | 2023 |
|[Text2Light: Zero-Shot Text-Driven HDR Panorama Generation](http://arxiv.org/abs/2209.09898) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2209.09898) | nan | nan | 2023 |
|[Text-to-3D using Gaussian Splatting](http://arxiv.org/abs/2309.16585) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2309.16585) | nan | nan | 2023 |
|[Autoregressive 3D Shape Generation via Canonical Mapping](http://arxiv.org/abs/2204.01955) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2204.01955) | nan | nan | 2022 |
|[SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation](https://openaccess.thecvf.com/content/CVPR2023/html/Cheng_SDFusion_Multimodal_3D_Shape_Completion_Reconstruction_and_Generation_CVPR_2023_paper.html) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://openaccess.thecvf.com/content/CVPR2023/html/Cheng_SDFusion_Multimodal_3D_Shape_Completion_Reconstruction_and_Generation_CVPR_2023_paper.html) | nan | nan | 2023 |
|[Efficient Text-Guided 3D-Aware Portrait Generation with Score Distillation Sampling on Distribution](http://arxiv.org/abs/2306.02083) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2306.02083) | nan | nan | 2023 |
|[Cross-Modal 3D Shape Generation and Manipulation](http://arxiv.org/abs/2207.11795) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2207.11795) | nan | nan | 2022 |
|[ITportrait: Image-Text Coupled 3D Portrait Domain Adaptation](http://arxiv.org/abs/2304.04364) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2304.04364) | nan | nan | 2023 |
|[FaceFormer: Speech-Driven 3D Facial Animation with Transformers](http://arxiv.org/abs/2112.05329) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2112.05329) | nan | nan | 2022 |
|[Ctrl-Room: Controllable Text-to-3D Room Meshes Generation with Layout Constraints](http://arxiv.org/abs/2310.03602) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2310.03602) | nan | nan | 2023 |
|[Text-guided 3D Human Generation from 2D Collections](http://arxiv.org/abs/2305.14312) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2305.14312) | nan | nan | 2023 |
|[TM2D: Bimodality Driven 3D Dance Generation via Music-Text Integration](https://openaccess.thecvf.com/content/ICCV2023/html/Gong_TM2D_Bimodality_Driven_3D_Dance_Generation_via_Music-Text_Integration_ICCV_2023_paper) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://openaccess.thecvf.com/content/ICCV2023/html/Gong_TM2D_Bimodality_Driven_3D_Dance_Generation_via_Music-Text_Integration_ICCV_2023_paper) | nan | nan | 2023 |
|[Semantify: Simplifying the Control of 3D Morphable Models using CLIP](http://arxiv.org/abs/2308.07415) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2308.07415) | nan | nan | 2023 |
|[Point-Bind & Point-LLM: Aligning Point Cloud with Multi-modality for 3D Understanding, Generation, and Instruction Following](http://arxiv.org/abs/2309.00615) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2309.00615) | nan | nan | 2023 |
|[Zero3D: Semantic-Driven Multi-Category 3D Shape Generation](http://arxiv.org/abs/2301.13591) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2301.13591) | nan | nan | 2023 |
|[HeadSculpt: Crafting 3D Head Avatars with Text](http://arxiv.org/abs/2306.03038) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2306.03038) | nan | nan | 2023 |
|[AI-enabled Automatic Multimodal Fusion of Cone-Beam CT and Intraoral Scans for Intelligent 3D Tooth-Bone Reconstruction and Clinical Applications](http://arxiv.org/abs/2203.05784) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2203.05784) | nan | nan | 2022 |
|[T$^3$Bench: Benchmarking Current Progress in Text-to-3D Generation](http://arxiv.org/abs/2310.02977) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2310.02977) | nan | nan | 2023 |
|[AvatarCLIP: Zero-Shot Text-Driven Generation and Animation of 3D Avatars](http://arxiv.org/abs/2205.08535) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2205.08535) | nan | nan | 2022 |
|[ArK: Augmented Reality with Knowledge Interactive Emergent Ability](http://arxiv.org/abs/2305.00970) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2305.00970) | nan | nan | 2023 |
|[AvatarFusion: Zero-shot Generation of Clothing-Decoupled 3D Avatars Using 2D Diffusion](http://arxiv.org/abs/2307.06526) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2307.06526) | nan | nan | 2023 |
|[SUG: Single-dataset Unified Generalization for 3D Point Cloud Classification](http://arxiv.org/abs/2305.09160) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2305.09160) | nan | nan | 2023 |
|[TextField3D: Towards Enhancing Open-Vocabulary 3D Generation with Noisy Text Fields](http://arxiv.org/abs/2309.17175) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2309.17175) | nan | nan | 2023 |
|[HumanNorm: Learning Normal Diffusion Model for High-quality and Realistic 3D Human Generation](http://arxiv.org/abs/2310.01406) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2310.01406) | nan | nan | 2023 |
|[DreamWaltz: Make a Scene with Complex 3D Animatable Avatars](http://arxiv.org/abs/2305.12529) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2305.12529) | nan | nan | 2023 |
|[Zero-Shot Text-Guided Object Generation with Dream Fields](http://arxiv.org/abs/2112.01455) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2112.01455) | nan | nan | 2022 |
|[ClipMatrix: Text-controlled Creation of 3D Textured Meshes](https://www.semanticscholar.org/paper/ClipMatrix%3A-Text-controlled-Creation-of-3D-Textured-Jetchev/8a8da11b42ed06f9ad393f96908723250a49a386) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://www.semanticscholar.org/paper/ClipMatrix%3A-Text-controlled-Creation-of-3D-Textured-Jetchev/8a8da11b42ed06f9ad393f96908723250a49a386) | nan | nan | 2021 |
|[AvatarCraft: Transforming Text into Neural Human Avatars with Parameterized Shape and Pose Control](http://arxiv.org/abs/2303.17606) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2303.17606) | nan | nan | 2023 |
|[3D-TOGO: Towards Text-Guided Cross-Category 3D Object Generation](http://arxiv.org/abs/2212.01103) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2212.01103) | nan | nan | 2023 |
|[CG-NeRF: Conditional Generative Neural Radiance Fields for 3D-aware Image Synthesis](https://ieeexplore.ieee.org/document/10030346) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://ieeexplore.ieee.org/document/10030346) | nan | nan | 2023 |
|[Shap-E: Generating Conditional 3D Implicit Functions](http://arxiv.org/abs/2305.02463) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2305.02463) | nan | nan | 2023 |
|[Instruct 3D-to-3D: Text Instruction Guided 3D-to-3D conversion](http://arxiv.org/abs/2303.15780) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2303.15780) | nan | nan | 2023 |
|[LERF: Language Embedded Radiance Fields](http://arxiv.org/abs/2303.09553) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2303.09553) | nan | nan | 2023 |
|[CLIP-Mesh: Generating textured meshes from text using pretrained image-text models](http://arxiv.org/abs/2203.13333) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2203.13333) | nan | nan | 2022 |
|[Chupa: Carving 3D Clothed Humans from Skinned Shape Priors using 2D Diffusion Probabilistic Models](http://arxiv.org/abs/2305.11870) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2305.11870) | nan | nan | 2023 |
|[DATID-3D: Diversity-Preserved Domain Adaptation Using Text-to-Image Diffusion for 3D Generative Model](http://arxiv.org/abs/2211.16374) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2211.16374) | nan | nan | 2023 |
|[PODIA-3D: Domain Adaptation of 3D Generative Model Across Large Domain Gap Using Pose-Preserved Text-to-Image Diffusion](http://arxiv.org/abs/2304.01900) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2304.01900) | nan | nan | 2023 |
|[MPE4G: Multimodal Pretrained Encoder for Co-Speech Gesture Generation](http://arxiv.org/abs/2305.15740) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2305.15740) | nan | nan | 2023 |
|[Decomposing NeRF for Editing via Feature Field Distillation](http://arxiv.org/abs/2205.15585) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2205.15585) | nan | nan | 2022 |
|[DreamHuman: Animatable 3D Avatars from Text](http://arxiv.org/abs/2306.09329) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2306.09329) | nan | nan | 2023 |
|[SALAD: Part-Level Latent Diffusion for 3D Shape Generation and Manipulation](http://arxiv.org/abs/2303.12236) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2303.12236) | nan | nan | 2023 |
|[Image-free Domain Generalization via CLIP for 3D Hand Pose Estimation](https://ieeexplore.ieee.org/document/10030743) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://ieeexplore.ieee.org/document/10030743) | nan | nan | 2023 |
|[3DDesigner: Towards Photorealistic 3D Object Generation and Editing with Text-guided Diffusion Models](http://arxiv.org/abs/2211.14108) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2211.14108) | nan | nan | 2023 |
|[Audio2Gestures: Generating Diverse Gestures from Audio](http://arxiv.org/abs/2301.06690) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2301.06690) | nan | nan | 2023 |
|[Audio2Gestures: Generating Diverse Gestures from Speech Audio with Conditional Variational Autoencoders](http://arxiv.org/abs/2108.06720) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2108.06720) | nan | nan | 2021 |
|[AI Choreographer: Music Conditioned 3D Dance Generation with AIST++](http://arxiv.org/abs/2101.08779) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2101.08779) | nan | nan | 2021 |
|[3D-CLFusion: Fast Text-to-3D Rendering with Contrastive Latent Diffusion](http://arxiv.org/abs/2303.11938) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2303.11938) | nan | nan | 2023 |
|[3DQD: Generalized Deep 3D Shape Prior via Part-Discretized Diffusion Process](http://arxiv.org/abs/2303.10406) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2303.10406) | nan | nan | 2023 |
|[AV-NeRF: Learning Neural Fields for Real-World Audio-Visual Scene Synthesis](http://arxiv.org/abs/2302.02088) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2302.02088) | nan | nan | 2023 |
|[Magic3D: High-Resolution Text-to-3D Content Creation](https://openaccess.thecvf.com/content/CVPR2023/html/Lin_Magic3D_High-Resolution_Text-to-3D_Content_Creation_CVPR_2023_paper.html) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://openaccess.thecvf.com/content/CVPR2023/html/Lin_Magic3D_High-Resolution_Text-to-3D_Content_Creation_CVPR_2023_paper.html) | nan | nan | 2023 |
|[CLIP-Layout: Style-Consistent Indoor Scene Synthesis with Semantic Furniture Embedding](http://arxiv.org/abs/2303.03565) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2303.03565) | nan | nan | 2023 |
|[3DALL-E: Integrating Text-to-Image AI in 3D Design Workflows](https://dl.acm.org/doi/10.1145/3563657.3596098) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://dl.acm.org/doi/10.1145/3563657.3596098) | nan | nan | 2023 |
|[StructDiffusion: Language-Guided Creation of Physically-Valid Structures using Unseen Objects](http://arxiv.org/abs/2211.04604) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2211.04604) | nan | nan | 2023 |
|[DreamStone: Image as a Stepping Stone for Text-Guided 3D Shape Generation](https://ieeexplore.ieee.org/document/10269027) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://ieeexplore.ieee.org/document/10269027) | nan | nan | 2023 |
|[ISS: Image as Stepping Stone for Text-Guided 3D Shape Generation](http://arxiv.org/abs/2209.04145) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2209.04145) | nan | nan | 2023 |
|[ATT3D: Amortized Text-to-3D Object Synthesis](http://arxiv.org/abs/2306.07349) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2306.07349) | nan | nan | 2023 |
|[Learning Versatile 3D Shape Generation with Improved AR Models](http://arxiv.org/abs/2303.14700) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2303.14700) | nan | nan | 2023 |
|[Revisiting Transformer for Point Cloud-based 3D Scene Graph Generation](http://arxiv.org/abs/2303.11048) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2303.11048) | nan | nan | 2023 |




## Pretraining



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[Multi-modal Relation Distillation for Unified 3D Representation Learning](https://arxiv.org/abs/2407.14007) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2407.14007) | nan | nan | 2024 |
|[CrossPoint: Self-Supervised Cross-Modal Contrastive Learning for 3D Point Cloud Understanding](https://ieeexplore.ieee.org/document/9878878) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://ieeexplore.ieee.org/document/9878878) | nan | nan | 2022 |
|[Grounding Pretrained Features in 3D Representations](https://openreview.net/forum?id=Lx7trKCpn6a) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://openreview.net/forum?id=Lx7trKCpn6a) | nan | nan | 2023 |
|[MedBLIP: Bootstrapping Language-Image Pre-training from 3D Medical Images and Texts](http://arxiv.org/abs/2305.10799) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2305.10799) | nan | nan | 2023 |
|[CrysMMNet: Multimodal Representation for Crystal Property Prediction](http://arxiv.org/abs/2307.05390) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2307.05390) | nan | nan | 2023 |
|[Joint-MAE: 2D-3D Joint Masked Autoencoders for 3D Point Cloud Pre-training](http://arxiv.org/abs/2302.14007) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2302.14007) | nan | nan | 2023 |
|[CHORUS: Learning Canonicalized 3D Human-Object Spatial Relations from Unbounded Synthesized Images](http://arxiv.org/abs/2308.12288) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2308.12288) | nan | nan | 2023 |
|[CLIP goes 3D: Leveraging Prompt Tuning for Language Grounded 3D Recognition](http://arxiv.org/abs/2303.11313) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2303.11313) | nan | nan | 2023 |
|[3D Concept Learning and Reasoning from Multi-View Images](http://arxiv.org/abs/2303.11327) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2303.11327) | nan | nan | 2023 |
|[3D-LLM: Injecting the 3D World into Large Language Models](http://arxiv.org/abs/2307.12981) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2307.12981) | nan | nan | 2023 |
|[Pri3D: Can 3D Priors Help 2D Representation Learning?](http://arxiv.org/abs/2104.11225) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2104.11225) | nan | nan | 2021 |
|[Joint Representation Learning for Text and 3D Point Cloud](http://arxiv.org/abs/2301.07584) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2301.07584) | nan | nan | 2023 |
|[CLIP2Point: Transfer CLIP to Point Cloud Classification with Image-Depth Pre-training](http://arxiv.org/abs/2210.01055) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2210.01055) | nan | nan | 2023 |
|[ConceptFusion: Open-set Multimodal 3D Mapping](http://arxiv.org/abs/2302.07241) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2302.07241) | nan | nan | 2023 |
|[MotionGPT: Human Motion as a Foreign Language](http://arxiv.org/abs/2306.14795) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2306.14795) | nan | nan | 2023 |
|[JM3D&JM3D-LLM: Elevating 3D Representation with Joint Multi-modal Cues](https://www.semanticscholar.org/paper/fbfba42906db022c9a0314aa618dde6c54723c62) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://www.semanticscholar.org/paper/fbfba42906db022c9a0314aa618dde6c54723c62) | nan | nan | 2023 |
|[Context-aware Alignment and Mutual Masking for 3D-Language Pre-training](https://ieeexplore.ieee.org/document/10203209/) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://ieeexplore.ieee.org/document/10203209/) | nan | nan | 2023 |
|[Point Clouds Are Specialized Images: A Knowledge Transfer Approach for 3D Understanding](http://arxiv.org/abs/2307.15569) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2307.15569) | nan | nan | 2023 |
|[ViT-Lens: Towards Omni-modal Representations](https://www.semanticscholar.org/paper/27e45a8aecc1fec246fd70c80d8f5104807cf0dd) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://www.semanticscholar.org/paper/27e45a8aecc1fec246fd70c80d8f5104807cf0dd) | nan | nan | 2023 |




## Editing and Manupulation



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[ClipFace: Text-guided Editing of Textured 3D Morphable Models](https://dl.acm.org/doi/10.1145/3588432.3591566) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://dl.acm.org/doi/10.1145/3588432.3591566) | nan | nan | 2023 |
|[CompoNeRF: Text-guided Multi-object Compositional NeRF with Editable 3D Scene Layout](http://arxiv.org/abs/2303.13843) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2303.13843) | nan | nan | 2023 |
|[Volumetric Disentanglement for 3D Scene Manipulation](http://arxiv.org/abs/2206.02776) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2206.02776) | nan | nan | 2022 |
|[Instruct-NeRF2NeRF: Editing 3D Scenes with Instructions](http://arxiv.org/abs/2303.12789) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2303.12789) | nan | nan | 2023 |
|[LADIS: Language Disentanglement for 3D Shape Editing](http://arxiv.org/abs/2212.05011) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2212.05011) | nan | nan | 2022 |
|[Local 3D Editing via 3D Distillation of CLIP Knowledge](https://ieeexplore.ieee.org/document/10205047/) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://ieeexplore.ieee.org/document/10205047/) | nan | nan | 2023 |





## detection



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[TransFusion: Robust LiDAR-Camera Fusion for 3D Object Detection with Transformers](https://ieeexplore.ieee.org/document/9879824/) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://ieeexplore.ieee.org/document/9879824/) | nan | nan | 2022 |
|[Omni3D: A Large Benchmark and Model for 3D Object Detection in the Wild](http://arxiv.org/abs/2207.10660) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2207.10660) | nan | nan | 2023 |
|[HRFuser: A Multi-resolution Sensor Fusion Architecture for 2D Object Detection](http://arxiv.org/abs/2206.15157) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2206.15157) | nan | nan | 2023 |
|[ObjectFusion: Multi-modal 3D Object Detection with Object-Centric Fusion](nan) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](nan) | nan | nan | 2023 |
|[PiMAE: Point Cloud and Image Interactive Masked Autoencoders for 3D Object Detection](https://ieeexplore.ieee.org/document/10204797/) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://ieeexplore.ieee.org/document/10204797/) | nan | nan | 2023 |
|[FUTR3D: A Unified Sensor Fusion Framework for 3D Detection](http://arxiv.org/abs/2203.10642) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2203.10642) | nan | nan | 2023 |
|[DSGN++: Exploiting Visual-Spatial Relation for Stereo-based 3D Detectors](http://arxiv.org/abs/2204.03039) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2204.03039) | nan | nan | 2022 |
|[FocalFormer3D : Focusing on Hard Instance for 3D Object Detection](http://arxiv.org/abs/2308.04556) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2308.04556) | nan | nan | 2023 |
|[Focal Sparse Convolutional Networks for 3D Object Detection](http://arxiv.org/abs/2204.12463) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2204.12463) | nan | nan | 2022 |
|[AutoAlignV2: Deformable Feature Aggregation for Dynamic Multi-Modal 3D Object Detection](http://arxiv.org/abs/2207.10316) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2207.10316) | nan | nan | 2022 |
|[BEVDistill: Cross-Modal BEV Distillation for Multi-View 3D Object Detection](http://arxiv.org/abs/2211.09386) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2211.09386) | nan | nan | 2022 |
|[Language-Guided 3D Object Detection in Point Cloud for Autonomous Driving](http://arxiv.org/abs/2305.15765) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2305.15765) | nan | nan | 2023 |
|[Semantics-aware LiDAR-Only Pseudo Point Cloud Generation for 3D Object Detection](http://arxiv.org/abs/2309.08932) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2309.08932) | nan | nan | 2023 |
|[A Generalized Multi-Modal Fusion Detection Framework](http://arxiv.org/abs/2303.07064) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2303.07064) | nan | nan | 2023 |
|[From Multi-View to Hollow-3D: Hallucinated Hollow-3D R-CNN for 3D Object Detection](http://arxiv.org/abs/2107.14391) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2107.14391) | nan | nan | 2021 |
|[DeepFusion: A Robust and Modular 3D Object Detector for Lidars, Cameras and Radars](http://arxiv.org/abs/2209.12729) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2209.12729) | nan | nan | 2022 |
|[PointSee: Image Enhances Point Cloud](http://arxiv.org/abs/2211.01664) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2211.01664) | nan | nan | 2022 |
|[FusionFormer: A Multi-sensory Fusion in Bird's-Eye-View and Temporal Consistent Transformer for 3D Object Detection](http://arxiv.org/abs/2309.05257) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2309.05257) | nan | nan | 2023 |
|[Joint Multi-Object Detection and Tracking with Camera-LiDAR Fusion for Autonomous Driving](http://arxiv.org/abs/2108.04602) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2108.04602) | nan | nan | 2021 |
|[Geometric-aware Pretraining for Vision-centric 3D Object Detection](http://arxiv.org/abs/2304.03105) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2304.03105) | nan | nan | 2023 |
|[TiG-BEV: Multi-view BEV 3D Object Detection via Target Inner-Geometry Learning](http://arxiv.org/abs/2212.13979) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2212.13979) | nan | nan | 2022 |
|[FULLER: Unified Multi-modality Multi-task 3D Perception via Multi-level Gradient Calibration](http://arxiv.org/abs/2307.16617) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2307.16617) | nan | nan | 2023 |
|[FaceCLIPNeRF: Text-driven 3D Face Manipulation using Deformable Neural Radiance Fields](http://arxiv.org/abs/2307.11418) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2307.11418) | nan | nan | 2023 |
|[Center Feature Fusion: Selective Multi-Sensor Fusion of Center-based Objects](http://arxiv.org/abs/2209.12880) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2209.12880) | nan | nan | 2023 |
|[SemanticBEVFusion: Rethink LiDAR-Camera Fusion in Unified Bird's-Eye View Representation for 3D Object Detection](http://arxiv.org/abs/2212.04675) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2212.04675) | nan | nan | 2022 |
|[MSMDFusion: Fusing LiDAR and Camera at Multiple Scales with Multi-Depth Seeds for 3D Object Detection](https://ieeexplore.ieee.org/document/10205088/) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://ieeexplore.ieee.org/document/10205088/) | nan | nan | 2023 |
|[Paint and Distill: Boosting 3D Object Detection with Semantic Passing Network](http://arxiv.org/abs/2207.05497) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2207.05497) | nan | nan | 2022 |
|[RCM-Fusion: Radar-Camera Multi-Level Fusion for 3D Object Detection](http://arxiv.org/abs/2307.10249) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2307.10249) | nan | nan | 2023 |
|[X 3 KD: Knowledge Distillation Across Modalities, Tasks and Stages for Multi-Camera 3D Object Detection](https://ieeexplore.ieee.org/document/10204976/) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://ieeexplore.ieee.org/document/10204976/) | nan | nan | 2023 |
|[Boosting Unsupervised Domain Adaptation for 3D Object Detection in Point Clouds with 2D Image Semantic Information](https://ieeexplore.ieee.org/abstract/document/10260428) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://ieeexplore.ieee.org/abstract/document/10260428) | nan | nan | 2023 |
|[LoGoNet: Towards Accurate 3D Object Detection with Local-to-Global Cross- Modal Fusion](https://ieeexplore.ieee.org/document/10205491/) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://ieeexplore.ieee.org/document/10205491/) | nan | nan | 2023 |
|[Homogeneous Multi-modal Feature Fusion and Interaction for 3D Object Detection](http://arxiv.org/abs/2210.09615) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2210.09615) | nan | nan | 2022 |
|[Unifying Voxel-based Representation with Transformer for 3D Object Detection](http://arxiv.org/abs/2206.00630) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2206.00630) | nan | nan | 2022 |
|[MoDAR: Using Motion Forecasting for 3D Object Detection in Point Cloud Sequences](https://ieeexplore.ieee.org/document/10205140/) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://ieeexplore.ieee.org/document/10205140/) | nan | nan | 2023 |
|[DeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object Detection](http://arxiv.org/abs/2203.08195) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2203.08195) | nan | nan | 2022 |
|[AShapeFormer: Semantics-Guided Object-Level Active Shape Encoding for 3D Object Detection via Transformers](https://openaccess.thecvf.com/content/CVPR2023/html/Li_AShapeFormer_Semantics-Guided_Object-Level_Active_Shape_Encoding_for_3D_Object_Detection_CVPR_2023_paper.html) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://openaccess.thecvf.com/content/CVPR2023/html/Li_AShapeFormer_Semantics-Guided_Object-Level_Active_Shape_Encoding_for_3D_Object_Detection_CVPR_2023_paper.html) | nan | nan | 2023 |
|[Delving into the Pre-training Paradigm of Monocular 3D Object Detection](http://arxiv.org/abs/2206.03657) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2206.03657) | nan | nan | 2022 |
|[MLF-DET: Multi-Level Fusion for Cross-Modal 3D Object Detection](http://arxiv.org/abs/2307.09155) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2307.09155) | nan | nan | 2023 |
|[Cross-Modal Analysis of Human Detection for Robotics: An Industrial Case Study](http://arxiv.org/abs/2108.01495) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2108.01495) | nan | nan | 2021 |
|[PAI3D: Painting Adaptive Instance-Prior for 3D Object Detection](http://arxiv.org/abs/2211.08055) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2211.08055) | nan | nan | 2022 |
|[EPNet++: Cascade Bi-directional Fusion for Multi-Modal 3D Object Detection](http://arxiv.org/abs/2112.11088) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2112.11088) | nan | nan | 2022 |
|[Multi-Modal 3D Object Detection by Box Matching](http://arxiv.org/abs/2305.07713) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2305.07713) | nan | nan | 2023 |
|[Open-Vocabulary 3D Detection via Image-level Class and Debiased Cross-modal Contrastive Learning](http://arxiv.org/abs/2207.01987) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2207.01987) | nan | nan | 2022 |
|[Open-Vocabulary Point-Cloud Object Detection without 3D Annotation](http://arxiv.org/abs/2304.00788) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2304.00788) | nan | nan | 2023 |
|[Open-Vocabulary Point-Cloud Object Detection Without 3D Annotation](https://openaccess.thecvf.com/content/CVPR2023/html/Lu_Open-Vocabulary_Point-Cloud_Object_Detection_Without_3D_Annotation_CVPR_2023_paper.html) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://openaccess.thecvf.com/content/CVPR2023/html/Lu_Open-Vocabulary_Point-Cloud_Object_Detection_Without_3D_Annotation_CVPR_2023_paper.html) | nan | nan | 2023 |




## Segmentation



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[A Simple and Robust Framework for Cross-Modality Medical Image Segmentation applied to Vision Transformers](http://arxiv.org/abs/2310.05572) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2310.05572) | nan | nan | 2023 |
|[MoPA: Multi-Modal Prior Aided Domain Adaptation for 3D Semantic Segmentation](http://arxiv.org/abs/2309.11839) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2309.11839) | nan | nan | 2023 |
|[Multi-Modal Continual Test-Time Adaptation for 3D Semantic Segmentation](http://arxiv.org/abs/2303.10457) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2303.10457) | nan | nan | 2023 |
|[Exploiting the Complementarity of 2D and 3D Networks to Address Domain-Shift in 3D Semantic Segmentation](http://arxiv.org/abs/2304.02991) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2304.02991) | nan | nan | 2023 |
|[Segment Anything in 3D with NeRFs](http://arxiv.org/abs/2304.12308) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2304.12308) | nan | nan | 2023 |
|[Context-Aware Entity Grounding with Open-Vocabulary 3D Scene Graphs](http://arxiv.org/abs/2309.15940) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2309.15940) | nan | nan | 2023 |
|[Optimal Latent Vector Alignment for Unsupervised Domain Adaptation in Medical Image Segmentation](http://arxiv.org/abs/2106.08188) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2106.08188) | nan | nan | 2021 |
|[MA-SAM: Modality-agnostic SAM Adaptation for 3D Medical Image Segmentation](http://arxiv.org/abs/2309.08842) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2309.08842) | nan | nan | 2023 |
|[Generative Text-Guided 3D Vision-Language Pretraining for Unified Medical Image Segmentation](https://arxiv.org/abs/2306.04811) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2306.04811) | nan | nan | 2023 |
|[LargeKernel3D: Scaling up Kernels in 3D Sparse CNNs](https://ieeexplore.ieee.org/document/10203060/) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://ieeexplore.ieee.org/document/10203060/) | nan | nan | 2023 |
|[PointDC:Unsupervised Semantic Segmentation of 3D Point Clouds via Cross-modal Distillation and Super-Voxel Clustering](http://arxiv.org/abs/2304.08965) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2304.08965) | nan | nan | 2023 |
|[UniDA3D: Unified Domain Adaptive 3D Semantic Segmentation Pipeline](http://arxiv.org/abs/2212.10390) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2212.10390) | nan | nan | 2023 |
|[MetaBEV: Solving Sensor Failures for BEV Detection and Map Segmentation](http://arxiv.org/abs/2304.09801) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2304.09801) | nan | nan | 2023 |
|[Swin UNETR: Swin Transformers for Semantic Segmentation of Brain Tumors in MRI Images](http://arxiv.org/abs/2201.01266) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2201.01266) | nan | nan | 2022 |
|[Prototype Adaption and Projection for Few- and Zero-Shot 3D Point Cloud Semantic Segmentation](https://ieeexplore.ieee.org/document/10138737) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://ieeexplore.ieee.org/document/10138737) | nan | nan | 2023 |
|[Mask3D: Pre-training 2D Vision Transformers by Learning Masked 3D Priors](http://arxiv.org/abs/2302.14746) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2302.14746) | nan | nan | 2023 |
|[OpenIns3D: Snap and Lookup for 3D Open-vocabulary Instance Segmentation](http://arxiv.org/abs/2309.00616) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2309.00616) | nan | nan | 2023 |
|[Contrastive Learning for Self-Supervised Pre-Training of Point Cloud Segmentation Networks With Image Data](http://arxiv.org/abs/2301.07283) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2301.07283) | nan | nan | 2023 |
|[Cross-modal Learning for Domain Adaptation in 3D Semantic Segmentation](http://arxiv.org/abs/2101.07253) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2101.07253) | nan | nan | 2022 |
|[Revisiting Multi-modal 3D Semantic Segmentation in Real-world Autonomous Driving](http://arxiv.org/abs/2310.08826) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2310.08826) | nan | nan | 2023 |
|[Language-guided Semantic Style Transfer of 3D Indoor Scenes](https://dl.acm.org/doi/10.1145/3552482.3556555) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://dl.acm.org/doi/10.1145/3552482.3556555) | nan | nan | 2022 |
|[2DDATA: 2D Detection Annotations Transmittable Aggregation for Semantic Segmentation on Point Cloud](http://arxiv.org/abs/2309.11755) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2309.11755) | nan | nan | 2023 |
|[Auto-Prompting SAM for Mobile Friendly 3D Medical Image Segmentation](http://arxiv.org/abs/2308.14936) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2308.14936) | nan | nan | 2023 |
|[MSeg3D: Multi-modal 3D Semantic Segmentation for Autonomous Driving](http://arxiv.org/abs/2303.08600) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2303.08600) | nan | nan | 2023 |
|[BEV-DG: Cross-Modal Learning under Bird's-Eye View for Domain Generalization of 3D Semantic Segmentation](http://arxiv.org/abs/2308.06530) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2308.06530) | nan | nan | 2023 |
|[CKD-TransBTS: Clinical Knowledge-Driven Hybrid Transformer with Modality-Correlated Cross-Attention for Brain Tumor Segmentation](http://arxiv.org/abs/2207.07370) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2207.07370) | nan | nan | 2022 |
|[Weakly Supervised 3D Open-vocabulary Segmentation](http://arxiv.org/abs/2305.14093) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2305.14093) | nan | nan | 2023 |
|[PartSLIP: Low-Shot Part Segmentation for 3D Point Clouds via Pretrained Image-Language Models](http://arxiv.org/abs/2212.01558) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2212.01558) | nan | nan | 2023 |
|[UniSeg: A Unified Multi-Modal LiDAR Segmentation Network and the OpenPCSeg Codebase](http://arxiv.org/abs/2309.05573) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2309.05573) | nan | nan | 2023 |




## Tracking



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[3D Multi-Object Tracking Using Graph Neural Networks with Cross-Edge Modality Attention](http://arxiv.org/abs/2203.10926) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2203.10926) | nan | nan | 2022 |
|[LATTE: LAnguage Trajectory TransformEr](http://arxiv.org/abs/2208.02918) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2208.02918) | nan | nan | 2022 |
|[3DMOTFormer: Graph Transformer for Online 3D Multi-Object Tracking](http://arxiv.org/abs/2308.06635) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2308.06635) | nan | nan | 2023 |
|[EagerMOT: 3D Multi-Object Tracking via Sensor Fusion](http://arxiv.org/abs/2104.14682) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2104.14682) | nan | nan | 2021 |
|[MMF-Track: Multi-modal Multi-level Fusion for 3D Single Object Tracking](http://arxiv.org/abs/2305.06794) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2305.06794) | nan | nan | 2023 |




## Matching



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[Self-Supervised Learning for Multimodal Non-Rigid 3D Shape Matching](http://arxiv.org/abs/2303.10971) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2303.10971) | nan | nan | 2023 |




## ov-detection



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[CoDA: Collaborative Novel Box Discovery and Cross-modal Alignment for Open-vocabulary 3D Object Detection](http://arxiv.org/abs/2310.02960) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2310.02960) | nan | nan | 2023 |




## Anomaly Detection



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[Complementary Pseudo Multimodal Feature for Point Cloud Anomaly Detection](http://arxiv.org/abs/2303.13194) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2303.13194) | nan | nan | 2023 |
|[EasyNet: An Easy Network for 3D Industrial Anomaly Detection](http://arxiv.org/abs/2307.13925) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2307.13925) | nan | nan | 2023 |




## Grounding



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[UniT3D: A Unified Transformer for 3D Dense Captioning and Visual Grounding](http://arxiv.org/abs/2212.00836) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2212.00836) | nan | nan | 2022 |
|[Learning Point-Language Hierarchical Alignment for 3D Visual Grounding](https://www.semanticscholar.org/paper/Learning-Point-Language-Hierarchical-Alignment-for-Chen-Luo/c4abd21df3ca0d7a7b59516fb7b6502c16edeec1) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://www.semanticscholar.org/paper/Learning-Point-Language-Hierarchical-Alignment-for-Chen-Luo/c4abd21df3ca0d7a7b59516fb7b6502c16edeec1) | nan | nan | 2022 |
|[ViewRefer: Grasp the Multi-view Knowledge for 3D Visual Grounding with GPT and Prototype Guidance](http://arxiv.org/abs/2303.16894) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2303.16894) | nan | nan | 2023 |
|[NS3D: Neuro-Symbolic Grounding of 3D Objects and Relations](https://openaccess.thecvf.com/content/CVPR2023/html/Hsu_NS3D_Neuro-Symbolic_Grounding_of_3D_Objects_and_Relations_CVPR_2023_paper.html) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://openaccess.thecvf.com/content/CVPR2023/html/Hsu_NS3D_Neuro-Symbolic_Grounding_of_3D_Objects_and_Relations_CVPR_2023_paper.html) | nan | nan | 2023 |
|[Multi-View Transformer for 3D Visual Grounding](http://arxiv.org/abs/2204.02174) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2204.02174) | nan | nan | 2022 |
|[Learning Point-Language Hierarchical Alignment for 3D Visual Grounding](https://www.semanticscholar.org/paper/814e4f45e605dc22e8fde9fee1ae66d55f5937a6) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://www.semanticscholar.org/paper/814e4f45e605dc22e8fde9fee1ae66d55f5937a6) | nan | nan | 2022 |
|[3D-SPS: Single-Stage 3D Visual Grounding via Referred Point Progressive Selection](https://ieeexplore.ieee.org/document/9878838) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://ieeexplore.ieee.org/document/9878838) | nan | nan | 2022 |
|[3D VR Sketch Guided 3D Shape Prototyping and Exploration](http://arxiv.org/abs/2306.10830) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2306.10830) | nan | nan | 2023 |




## Completion



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[AGG-Net: Attention Guided Gated-convolutional Network for Depth Image Completion](http://arxiv.org/abs/2309.01624) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2309.01624) | nan | nan | 2023 |




## Style-Transfer



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[TeSTNeRF: Text-Driven 3D Style Transfer via Cross-Modal Learning](https://www.ijcai.org/proceedings/2023/642) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://www.ijcai.org/proceedings/2023/642) | nan | nan | 2023 |
|[TANGO: Text-driven Photorealistic and Robust 3D Stylization via Lighting Decomposition](http://arxiv.org/abs/2210.11277) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2210.11277) | nan | nan | 2022 |
|[HyperStyle3D: Text-Guided 3D Portrait Stylization via Hypernetworks](http://arxiv.org/abs/2304.09463) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2304.09463) | nan | nan | 2023 |
|[CLIP3Dstyler: Language Guided 3D Arbitrary Neural Style Transfer](http://arxiv.org/abs/2305.15732) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2305.15732) | nan | nan | 2023 |




## Pose Estimation



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[ZeroPose: CAD-Model-based Zero-Shot Pose Estimation](http://arxiv.org/abs/2305.17934) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2305.17934) | nan | nan | 2023 |
|[Weakly Supervised 3D Multi-person Pose Estimation for Large-scale Scenes based on Monocular Camera and Single LiDAR](http://arxiv.org/abs/2211.16951) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2211.16951) | nan | nan | 2022 |
|[PoseScript: 3D Human Poses from Natural Language](http://arxiv.org/abs/2210.11795) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2210.11795) | nan | nan | 2022 |
|[PoseFix: Correcting 3D Human Poses with Natural Language](http://arxiv.org/abs/2309.08480) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2309.08480) | nan | nan | 2023 |
|[Human-M3: A Multi-view Multi-modal Dataset for 3D Human Pose Estimation in Outdoor Scenes](http://arxiv.org/abs/2308.00628) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2308.00628) | nan | nan | 2023 |
|[CLIP-Hand3D: Exploiting 3D Hand Pose Estimation via Context-Aware Prompting](http://arxiv.org/abs/2309.16140) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2309.16140) | nan | nan | 2023 |
|[Non-Local Latent Relation Distillation for Self-Adaptive 3D Human Pose Estimation](http://arxiv.org/abs/2204.01971) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2204.01971) | nan | nan | 2022 |
|[Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation](http://arxiv.org/abs/2110.11680) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2110.11680) | nan | nan | 2021 |
|[Cross-Domain 3D Hand Pose Estimation with Dual Modalities](https://ieeexplore.ieee.org/document/10203772/) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://ieeexplore.ieee.org/document/10203772/) | nan | nan | 2023 |
|[3D-Augmented Contrastive Knowledge Distillation for Image-based Object Pose Estimation](http://arxiv.org/abs/2206.02531) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2206.02531) | nan | nan | 2022 |




## Scene Understanding



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[Towards Label-free Scene Understanding by Vision Foundation Models](http://arxiv.org/abs/2306.03899) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2306.03899) | nan | nan | 2023 |
|[CLIP2Scene: Towards Label-efficient 3D Scene Understanding by CLIP](https://ieeexplore.ieee.org/document/10204547/) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://ieeexplore.ieee.org/document/10204547/) | nan | nan | 2023 |
|[Semantics-guided Transformer-based Sensor Fusion for Improved Waypoint Prediction](http://arxiv.org/abs/2308.02126) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2308.02126) | nan | nan | 2023 |
|[Lowis3D: Language-Driven Open-World Instance-Level 3D Scene Understanding](http://arxiv.org/abs/2308.00353) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2308.00353) | nan | nan | 2023 |
|[PLA: Language-Driven Open-Vocabulary 3D Scene Understanding](http://arxiv.org/abs/2211.16312) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2211.16312) | nan | nan | 2023 |
|[Semantic Abstraction: Open-World 3D Scene Understanding from 2D Vision-Language Models](http://arxiv.org/abs/2207.11514) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2207.11514) | nan | nan | 2022 |
|[OpenShape: Scaling Up 3D Shape Representation Towards Open-World Understanding](http://arxiv.org/abs/2305.10764) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2305.10764) | nan | nan | 2023 |




## Manupulation



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[PolarNet: 3D Point Clouds for Language-Guided Robotic Manipulation](http://arxiv.org/abs/2309.15596) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2309.15596) | nan | nan | 2023 |
|[TextDeformer: Geometry Manipulation using Text Guidance](http://arxiv.org/abs/2304.13348) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2304.13348) | nan | nan | 2023 |
|[Act3D: 3D Feature Field Transformers for Multi-Task Robotic Manipulation](https://www.semanticscholar.org/paper/Act3D%3A-3D-Feature-Field-Transformers-for-Multi-Task-Gervet-Xian/7275318008bad0c141d3516a25903b37014590a1) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://www.semanticscholar.org/paper/Act3D%3A-3D-Feature-Field-Transformers-for-Multi-Task-Gervet-Xian/7275318008bad0c141d3516a25903b37014590a1) | nan | nan | 2023 |




## Retrival



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[Democratising 2D Sketch to 3D Shape Retrieval Through Pivoting](https://openaccess.thecvf.com/content/ICCV2023/html/Chowdhury_Democratising_2D_Sketch_to_3D_Shape_Retrieval_Through_Pivoting_ICCV_2023_paper.html) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://openaccess.thecvf.com/content/ICCV2023/html/Chowdhury_Democratising_2D_Sketch_to_3D_Shape_Retrieval_Through_Pivoting_ICCV_2023_paper.html) | nan | nan | 2023 |
|[RONO: Robust Discriminative Learning With Noisy Labels for 2D-3D Cross-Modal Retrieval](https://openaccess.thecvf.com/content/CVPR2023/html/Feng_RONO_Robust_Discriminative_Learning_With_Noisy_Labels_for_2D-3D_Cross-Modal_CVPR_2023_paper.html) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://openaccess.thecvf.com/content/CVPR2023/html/Feng_RONO_Robust_Discriminative_Learning_With_Noisy_Labels_for_2D-3D_Cross-Modal_CVPR_2023_paper.html) | nan | nan | 2023 |
|[TextANIMAR: Text-based 3D Animal Fine-Grained Retrieval](http://arxiv.org/abs/2304.06053) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2304.06053) | nan | nan | 2023 |
|[SCA-PVNet: Self-and-Cross Attention Based Aggregation of Point Cloud and Multi-View for 3D Object Retrieval](http://arxiv.org/abs/2307.10601) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2307.10601) | nan | nan | 2023 |
|[OVIR-3D: Open-Vocabulary 3D Instance Retrieval Without Training on 3D Data](https://openreview.net/forum?id=gVBvtRqU1_) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://openreview.net/forum?id=gVBvtRqU1_) | nan | nan | 2023 |
|[Towards 3D VR-Sketch to 3D Shape Retrieval](http://arxiv.org/abs/2209.10020) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2209.10020) | nan | nan | 2022 |




## Classification



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[Multimodal Brain Disease Classification with Functional Interaction Learning from Single fMRI Volume](http://arxiv.org/abs/2208.03028) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2208.03028) | nan | nan | 2023 |




## Localization



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[3D Highlighter: Localizing Regions on 3D Shapes via Text Descriptions](https://ieeexplore.ieee.org/document/10205282/) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://ieeexplore.ieee.org/document/10205282/) | nan | nan | 2023 |
|[UnLoc: A Universal Localization Method for Autonomous Vehicles using LiDAR, Radar and/or Camera Input](http://arxiv.org/abs/2307.00741) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2307.00741) | nan | nan | 2023 |
|[WildRefer: 3D Object Localization in Large-scale Dynamic Scenes with Multi-modal Visual Data and Natural Language](http://arxiv.org/abs/2304.05645) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2304.05645) | nan | nan | 2023 |




## Question Answering



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[Multi-CLIP: Contrastive Vision-Language Pre-training for Question Answering tasks in 3D Scenes](http://arxiv.org/abs/2306.02329) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2306.02329) | nan | nan | 2023 |




## Prediction



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[3D Spatial Multimodal Knowledge Accumulation for Scene Graph Prediction in Point Cloud](https://ieeexplore.ieee.org/document/10204093/) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://ieeexplore.ieee.org/document/10204093/) | nan | nan | 2023 |




## Depth Estimation



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[Towards Zero-Shot Scale-Aware Monocular Depth Estimation](http://arxiv.org/abs/2306.17253) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2306.17253) | nan | nan | 2023 |




## Finetuning



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[ImageBind-LLM: Multi-modality Instruction Tuning](http://arxiv.org/abs/2309.03905) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2309.03905) | nan | nan | 2023 |




## Recognition



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[LiCamGait: Gait Recognition in the Wild by Using LiDAR and Camera Multi-modal Visual Sensors](http://arxiv.org/abs/2211.12371) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2211.12371) | nan | nan | 2022 |
|[LATFormer: Locality-Aware Point-View Fusion Transformer for 3D Shape Recognition](http://arxiv.org/abs/2109.01291) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2109.01291) | nan | nan | 2023 |
|[Cross-Modal Learning with 3D Deformable Attention for Action Recognition](http://arxiv.org/abs/2212.05638) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2212.05638) | nan | nan | 2023 |
|[FER-former: Multi-modal Transformer for Facial Expression Recognition](https://www.semanticscholar.org/paper/c4e4fbb42a960b903d4c746623a1e364687a0091) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://www.semanticscholar.org/paper/c4e4fbb42a960b903d4c746623a1e364687a0091) | nan | nan | 2023 |




## Reconstruction



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[Speech4Mesh: Speech-Assisted Monocular 3D Facial Reconstruction for Speech-Driven 3D Facial Animation](https://openaccess.thecvf.com/content/ICCV2023/html/He_Speech4Mesh_Speech-Assisted_Monocular_3D_Facial_Reconstruction_for_Speech-Driven_3D_Facial_ICCV_2023_paper) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://openaccess.thecvf.com/content/ICCV2023/html/He_Speech4Mesh_Speech-Assisted_Monocular_3D_Facial_Reconstruction_for_Speech-Driven_3D_Facial_ICCV_2023_paper) | nan | nan | 2023 |
|[Zero-1-to-3: Zero-shot One Image to 3D Object](http://arxiv.org/abs/2303.11328) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2303.11328) | nan | nan | 2023 |




## Style Generation



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[Style-aware Augmented Virtuality Embeddings (SAVE)](https://ieeexplore.ieee.org/document/10108488) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://ieeexplore.ieee.org/document/10108488) | nan | nan | 2023 |




## Scene Understanding



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[M$^{3}$3D: Learning 3D priors using Multi-Modal Masked Autoencoders for 2D image and video understanding](http://arxiv.org/abs/2309.15313) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2309.15313) | nan | nan | 2023 |




## Captioning



| Title | arXiv | Github | WebSite | Pub. & Date |
|-----|:-----:|:-----:|:-----:|:-----:|
|[Scalable 3D Captioning with Pretrained Models](http://arxiv.org/abs/2306.07279) | [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2306.07279) | nan | nan | 2023 |
